# Week 1

_"Computers are universal machines"_ - Turing

_"Probably approximately Correct"_ - book suggestion

- Hardware of the mind - built in functionality
- Instinct vs Intelligence
- Instinct is based off of previous generations' Intelligence

ML - trying to find a balance between many inter-related variables

Thermodynamics have influenced ML. Creating an equilibrium of a space's temperature.

When we see the world, that is a data visualization. . .of photons and our eyes process them

## [Immanuel Kant](https://en.wikipedia.org/wiki/Immanuel_Kant) - rationalism and empiricism

- Rationalism: everything that can be known, can be known because it is true, and the universe has created it as 'real'
- Empiricist: everything you know is from experience.
- Kant says they are each partly correct. We have a common operating system : **Time, Space, Causality**
- Judgment is not arbitrary. We're in the same system of reality, but some are pure opinion.
- **Neumena** : 'the thing in itself', 'the world aside from perception'
- **Phenomena**: the world as it is perceived.

Calculus - the rate of change.

Machine memorization vs machine learning

## Categories

1) **Supervised Learning** - you know the output you want. Give it lots of examples of correct solutions. These can be **classification** assignments or **regression** assignments. Regression is non-discrete, but the output is a valued number.

2) **Unsupervised Learning** - a set of example inputs are provided, but you don't know the output. Want system to pick up on sub patterns. Trying to get machine to produce representation of those.

3) **Semi-supervised Learning** - unsupervised assists the supervised problem. Supervised system might not be large enough. It's very granular information in relationship to a high-level concept. Find patterns in the unsupervised set, then send that to the supervised set.

4) **Reinforcement Learning** - like how you train a dog. You're shaping behavioral output, with rewards and punishments. Tune the behavior.

'Alpha Go' is unsupervised layers with reinforcement.

[Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton)

Deep Belief Network - stacked encoders (restricted boltzman architecture)

RB -2 layers - visible and hidden. visible has same dimensions of the world. A photo of a leaf: 32x32px 1024 pixels, greyscale only. Hidden - lets make lower level representations. less dimensions than in the visible. Pass info from visible to hidden and vice versa. chain of generalization.

## Run-length encoding

Lossless vs lossy.

- Run length is lossless.

## Homework

takes a string as an input and outputs an encoded string If you can, go the other direction
